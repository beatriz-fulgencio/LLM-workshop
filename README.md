# LLM Workshop Resources

A curated collection of readings, tutorials, and tools to support both the theory and practice of large language models. Organized by topic for quick navigation.
---

## ğŸ““ Workshop Materials

- **Slides:** `IntroLLMs.pdf`
- **Notebook:** `class1.ipynb` â€” Colab exercises on tokenization, embeddings, SFT & RAG

---

## ğŸ“š Foundations & Theory

- **[CSÂ 597G: Large Language Models (Princeton, Fall â€™22)](https://www.cs.princeton.edu/courses/archive/fall22/cos597G/)**  
  Lecture notes and assignments covering the mathematics and algorithms behind LLMs.  
- **[CSâ€¯324: Modeling with LLMs (Stanford, Winter â€™22)](https://stanford-cs324.github.io/winter2022/lectures/modeling/)**  
  Slides on probabilistic and transformerâ€‘based language modeling.  
- **[Attention Is All You Need (Portuguese translation)](https://medium.com/@msmurilo/traduÃ§Ã£o-artigo-attention-is-all-you-need-2f7a4113b3be)**  
  The seminal transformer paper, translated and annotated in portuguese.
- **[Google Crash Course: LLMs](https://developers.google.com/machine-learning/crash-course/llm)**  
  Biteâ€‘sized videos on training and deploying basic language models.   

---

## ğŸ”§ Fineâ€‘Tuning & Adaptation

- **[A Comprehensive Introduction to Fineâ€‘Tuning LLMs](https://medium.com/@sahin.sa...a/a-comprehensive-introduction-to-fine-tuning-llms-4d1bcc95a83a)**  
  Stepâ€‘byâ€‘step guide to full vs. parameterâ€‘efficient fineâ€‘tuning methods.  
- **[LLM Bootcamp (Full Stack Deep Learning)](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/#llm-foundations)**  
  Handsâ€‘on tutorials on LoRA, adapters, and prefixâ€‘tuning.
- **[Awesome LLM (Hannibal046)](https://github.com/Hannibal046/Awesome-LLM?tab=readme-ov-file)**  
  A GitHub repo aggregating tools for embedding, retrieval, and RAG pipelines.  

---

## ğŸ¨ Visualization & Other Resources

- **[LLM Diagrams & Animations](https://bbycroft.net/llm)**  
  Interactive illustrations of transformer internals and token flow.
- **[Tiktokenizer](https://tiktokenizer.vercel.app/)**
  Iterative token simulator. 
- **[ULTRACHAÅ¦ Map (Nomic Atlas)](https://atlas.nomic.ai/data/stingning/ultrachat-1/map)**  
  Visualization of postâ€‘training conversation data and labeling workflows.
- [Hugging Face Inference playground](https://huggingface.co/spaces/huggingface/inference-playground)
  Web-based interface that allows users to interact with models hosted on the Hugging Face Hub without writing any code.
- **[Resources to Master LLMs (KDnuggets)](https://www.kdnuggets.com/a-comprehensive-list-of-resources-to-master-large-language-models)**  
  Aggregated tutorials, blog posts, and video playlists.
- **[FineWeb (pretraining dataset)](https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1)**
  Internet scan database used for pretraining.
- **[LLM arena for model ranking](https://lmarena.ai)**
  Comparisson of sota models.
- **[LLM studio for running models locally](https://lmstudio.ai)**
  Local AI toolkit for local models.

---

## ğŸ¥ Video Lectures

- **[Andrej Karpathy: â€œTransformers from Scratchâ€](https://www.youtube.com/watch?v=7xTGNNLPyMI&t=69s)**  
  Intuitive walkthrough of transformer architectures and selfâ€‘attention.  

---


## ğŸ¤ Contributing

Feel free to suggest new resources or fixes via pull requests! Or get in contact with creator! 
